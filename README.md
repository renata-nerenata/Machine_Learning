# Machine_Learning
This repository presents exciting projects using machine learning or interesting theoretical aspects.

## Akaike information criterion (AIC)

The Akaike information criterion is an estimator of out-of-sample prediction error and thereby relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. 

Regression model is
<img src="http://latex2png.com/pngs/6a16c6466cb7d4ff8c0fc4c38339ca6c.png" width="300"/>



and <img src="http://latex2png.com/pngs/a585fca649d15ba28f30dc4b15455a2d.png" width="100"/> is dictributed normally: <img src="http://latex2png.com/pngs/cdc9a61937624354c56bfcb0061a33b9.png" width="100"/> is known.

Prove that the model with highest Akaike information criterion is the model with smallest Mallow's <img src="http://latex2png.com/pngs/9f3d4296f92bcac8fd4935bc1a06ddbb.png" width="100"/>
