# Machine_Learning
This repository presents exciting projects using machine learning or interesting theoretical aspects.

## Model Selection

### Akaike information criterion (AIC)

The Akaike information criterion is an estimator of out-of-sample prediction error and thereby relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. 

Mallowâ€™s <img src="http://latex2png.com/pngs/9f3d4296f92bcac8fd4935bc1a06ddbb.png" width="50"/> is a technique for model selection in regression. The <img src="http://latex2png.com/pngs/9f3d4296f92bcac8fd4935bc1a06ddbb.png" width="50"/> statistic is defined as a criteria to assess fits when models with different numbers of parameters are being compared.

Regression model is

<img src="http://latex2png.com/pngs/6a16c6466cb7d4ff8c0fc4c38339ca6c.png" width="200"/>

and <img src="http://latex2png.com/pngs/a585fca649d15ba28f30dc4b15455a2d.png" width="10"/> is dictributed normally: <img src="http://latex2png.com/pngs/cdc9a61937624354c56bfcb0061a33b9.png" width="100"/> is known.

Prove that the model with highest Akaike information criterion is the model with smallest Mallow's <img src="http://latex2png.com/pngs/9f3d4296f92bcac8fd4935bc1a06ddbb.png" width="50"/>


